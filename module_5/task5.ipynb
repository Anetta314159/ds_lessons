{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4e023b-82c6-4336-8224-555e916ca1ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](task5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d984a68-1758-4d04-ba2d-fa5c079e4ae1",
   "metadata": {},
   "source": [
    "## 1.\tОбучите простую рекуррентную нейронную сеть (без GRU/LSTM, без внимания) решать задачу дешифровки шифра Цезаря."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2591a9-f007-4472-bea9-87f7a5868ef9",
   "metadata": {},
   "source": [
    "<br>1. Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на N каждой буквы).\n",
    "Например, если N=2, то буква A переходит в букву C.\n",
    "Можно поиграться с языком на выбор (немецкий, русский и т. д.).\n",
    "<br>2. Создать архитектуру рекуррентной нейронной сети.\n",
    "<br>3. Обучить её (вход — зашифрованная фраза, выход — дешифрованная фраза).\n",
    "<br>4. Проверить качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffdf9b4-4056-4898-b9f5-4a1589902537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d17d9f3-a810-48db-9d49-3a50a52e982c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d151a39-2e55-4f54-8c1f-555e500487a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, LSTM, GRU, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import string\n",
    "import random\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece0a01d-0af5-4a4e-856b-51d44916e758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4371914c-bfec-4da4-8b31-72fdf013aaff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/anetta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c468585-6b3e-43c5-bea3-f2e809795838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_cipher(text, shift, alphabet):\n",
    "    \"\"\"\n",
    "    Функция для шифрования текста с использованием шифра Цезаря.\n",
    "    \n",
    "    :param text: Исходный текст для шифрования.\n",
    "    :param shift: Смещение по алфавиту.\n",
    "    :param alphabet: Алфавит, используемый для шифрования.\n",
    "    :return: Зашифрованный текст.\n",
    "    \"\"\"\n",
    "    shifted_text = \"\".join(\n",
    "        alphabet[(alphabet.index(c) + shift) % len(alphabet)] if c in alphabet else c for c in text\n",
    "    )\n",
    "    return shifted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0c7957-43da-46e4-97b8-bf6045db7e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dec7e39-1b0d-4861-a139-3f510a7f8cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'бвгдеё'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caesar_cipher('абвгде', 1, alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ea00ed-a888-4717-8780-64c1ec9c1900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/anetta/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "text_samples = gutenberg.sents('austen-emma.txt')[:1000]  \n",
    "text_samples = [\" \".join(sent).lower() for sent in text_samples if len(sent) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1365c7f1-2959-4403-8c7f-cc0802910f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[ emma by jane austen 1816 ]',\n",
       " 'emma woodhouse , handsome , clever , and rich , with a comfortable home and happy disposition , seemed to unite some of the best blessings of existence ; and had lived nearly twenty - one years in the world with very little to distress or vex her .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3ff9ae-c2fd-4bee-b453-133deacdf60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz \"\n",
    "shift = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c202769c-e663-47b4-adc5-27048ccdacc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = [caesar_cipher(text, shift, alphabet) for text in text_samples]\n",
    "y = text_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08eac203-ad80-40d6-bf64-33b22a79deb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(text, char_to_index):\n",
    "    \"\"\"\n",
    "    Преобразует текст в последовательность индексов на основе заданного словаря символов.\n",
    "    \n",
    "    :param text: Входной текст.\n",
    "    :param char_to_index: Словарь, сопоставляющий символы их индексам.\n",
    "    :return: Список индексов, представляющих входной текст.\n",
    "    \"\"\"\n",
    "    return [char_to_index[char] for char in text if char in char_to_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2b7cdd-ab48-474a-bb5b-7d44c715b5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "char_to_index = {char: i for i, char in enumerate(alphabet)}\n",
    "index_to_char = {i: char for char, i in char_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a1e228d-889c-4665-b4cb-d8b921fd9d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_seq = [text_to_sequence(text, char_to_index) for text in X]\n",
    "y_seq = [text_to_sequence(text, char_to_index) for text in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c37b082-2b02-44e0-8a0b-21878382a70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Заполним последовательности до одинаковой длины\n",
    "max_len = max(len(seq) for seq in X_seq)\n",
    "X_seq = tf.keras.preprocessing.sequence.pad_sequences(X_seq, maxlen=max_len, padding='post')\n",
    "y_seq = tf.keras.preprocessing.sequence.pad_sequences(y_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0bd334e-18aa-4df1-9674-f5dd3a4fed51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc209731-6afd-4afc-bc54-910728633c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(alphabet)\n",
    "embedding_dim = 8\n",
    "hidden_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca4cfab7-2402-46e6-a815-d56e89a97874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    SimpleRNN(hidden_units, return_sequences=True),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3f7bcd5-8709-4393-b178-98e6af7d12b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65f797b3-f854-497a-b389-763abd861944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.8170 - loss: 1.0586 - val_accuracy: 0.8826 - val_loss: 0.4033\n",
      "Epoch 2/5\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9011 - loss: 0.3526 - val_accuracy: 0.9387 - val_loss: 0.2611\n",
      "Epoch 3/5\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9510 - loss: 0.2214 - val_accuracy: 0.9729 - val_loss: 0.1315\n",
      "Epoch 4/5\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.9802 - loss: 0.1022 - val_accuracy: 0.9898 - val_loss: 0.0562\n",
      "Epoch 5/5\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9925 - loss: 0.0434 - val_accuracy: 0.9959 - val_loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x313c957d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=4, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "315751a7-1ef7-4421-826b-7a5356ab2fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9960 - loss: 0.0275\n",
      "Test accuracy: 0.9959\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ae78320-1856-445d-9f7a-4e93fd503778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_sequence(model, input_text, char_to_index, index_to_char, max_len):\n",
    "    \"\"\"\n",
    "    Декодирует зашифрованную последовательность с помощью обученной модели.\n",
    "    \n",
    "    :param model: Обученная нейросеть.\n",
    "    :param input_text: Зашифрованный текст.\n",
    "    :param char_to_index: Словарь преобразования символов в индексы.\n",
    "    :param index_to_char: Словарь преобразования индексов в символы.\n",
    "    :param max_len: Максимальная длина последовательности.\n",
    "    :return: Декодированный текст.\n",
    "    \"\"\"\n",
    "    input_seq = text_to_sequence(input_text, char_to_index)\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences([input_seq], maxlen=max_len, padding='post')\n",
    "    predicted_seq = model.predict(input_seq)\n",
    "    predicted_chars = [index_to_char[np.argmax(vec)] for vec in predicted_seq[0]]\n",
    "    return \"\".join(predicted_chars).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2794f0a1-31c8-4d99-8d14-bfff9d68d5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Зашифрованное: khoorczruog\n",
      "Расшифрованное: hello world\n"
     ]
    }
   ],
   "source": [
    "text = \"hello world\"\n",
    "example_encrypted = caesar_cipher(text, shift, alphabet)\n",
    "example_decrypted = decode_sequence(model, example_encrypted, char_to_index, index_to_char, len(text))\n",
    "print(f'Зашифрованное: {example_encrypted}')\n",
    "print(f'Расшифрованное: {example_decrypted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09c73b-8593-4fbc-9ff7-9bf2a2f39536",
   "metadata": {},
   "source": [
    "## 2.\tСгенерировать последовательности, которые состоят из цифр (от 0 до 9) и задаются следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8259db0-fcc7-4c2f-8c78-410914136264",
   "metadata": {},
   "source": [
    " x  - последовательность цифр,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1a322-7f13-4a97-8730-2ff419931a4f",
   "metadata": {},
   "source": [
    "$$ y_1 = x_1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5554b-765f-4023-a2e7-1cf35f4b17fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$ y_i = x_i + x_{i-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab7346-06ed-483e-9c16-a8e0e35b2190",
   "metadata": {
    "tags": []
   },
   "source": [
    "Если  $$ y_i \\geq 10 $$ , то  $$ y_i = y_i - 10 $$\n",
    "Научить модель рекуррентной нейронной сети предсказывать  $ y_i $  по  $ x_i $\n",
    "Использовать: RNN, LSTM, GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "355a4c60-b8a7-4451-8182-6f2209c8a379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_sequences(n_samples=10000, seq_length=10):\n",
    "    \"\"\"\n",
    "    Генерирует случайные последовательности, которые состоят из цифр (от 0 до 9).\n",
    "    \n",
    "        n_samples (int): Количество последовательностей.\n",
    "        seq_length (int): Длина каждой последовательности.\n",
    "    \n",
    "    Return:\n",
    "        X (np.array): Исходные последовательности.\n",
    "        Y (np.array): Преобразованные последовательности.\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for _ in range(n_samples):\n",
    "        x = np.random.randint(0, 10, seq_length)\n",
    "        y = np.zeros_like(x)\n",
    "        y[0] = x[0]\n",
    "        for i in range(1, seq_length):\n",
    "            y[i] = (x[i] + x[i - 1]) % 10  \n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e51c4ed-c45c-4cb6-a049-317595e32686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, Y = generate_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30b0d5f9-5ca9-4d03-ba57-5fce461b5239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcaa89e4-1f34-44a9-b078-66dea0d1465c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "519b951f-2180-43e2-bdfb-1ecf1b915812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 0, 3, 1, 6, 6, 0, 9, 3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07e9fc38-9ce7-4a79-be2e-39dd72514103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 7, 3, 3, 4, 7, 2, 6, 9, 2]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7db0569-e5bd-4091-b0a4-43670db0f637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 10), (10000, 10))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653b461b-4949-4c0f-a170-957febef639b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41b780d1-1a56-4e24-a81d-8372dd7be2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "#model_rnn.add(Bidirectional(SimpleRNN(50, activation='relu', return_sequences=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3931f9e2-d2e8-4eb0-b671-98777907cd7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RNN\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(50, activation='relu', return_sequences=True))\n",
    "model_rnn.add(Dense(10, activation='softmax'))\n",
    "model_rnn.compile(optimizer='adam', metrics=['accuracy'], loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "484ce394-0afd-4cc7-9eda-664f325462f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1244 - loss: 2.3298 - val_accuracy: 0.1837 - val_loss: 2.1320\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2165 - loss: 2.0665 - val_accuracy: 0.3350 - val_loss: 1.8299\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3823 - loss: 1.7520 - val_accuracy: 0.5009 - val_loss: 1.5434\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5269 - loss: 1.4802 - val_accuracy: 0.5977 - val_loss: 1.3258\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6217 - loss: 1.2671 - val_accuracy: 0.6382 - val_loss: 1.1428\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6864 - loss: 1.0855 - val_accuracy: 0.7418 - val_loss: 0.9796\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7548 - loss: 0.9430 - val_accuracy: 0.7998 - val_loss: 0.8630\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8075 - loss: 0.8273 - val_accuracy: 0.8219 - val_loss: 0.7597\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8471 - loss: 0.7254 - val_accuracy: 0.8889 - val_loss: 0.6711\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8754 - loss: 0.6452 - val_accuracy: 0.8922 - val_loss: 0.5957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x313a8be50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6586b5b9-3633-402d-9fb5-43eec03aac31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.8942 - loss: 0.5969\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_rnn.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72892536-b681-41b7-8b98-fda3d597d8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['RNN'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "372d9fcc-7ecf-48fc-9b93-c916f5c17451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model_lstm.add(Dense(10, activation='softmax'))\n",
    "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9020bca3-d014-4bf5-93a2-b246c2c91db9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1024 - loss: 2.3094 - val_accuracy: 0.1375 - val_loss: 2.2435\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1606 - loss: 2.1786 - val_accuracy: 0.2971 - val_loss: 1.8471\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3652 - loss: 1.6742 - val_accuracy: 0.5511 - val_loss: 1.2558\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 1.1418 - val_accuracy: 0.7281 - val_loss: 0.8943\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7618 - loss: 0.8341 - val_accuracy: 0.8315 - val_loss: 0.6863\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.6446 - val_accuracy: 0.8480 - val_loss: 0.5654\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.5017 - val_accuracy: 0.9077 - val_loss: 0.4557\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.4044 - val_accuracy: 0.9548 - val_loss: 0.3337\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.3179 - val_accuracy: 0.9649 - val_loss: 0.2859\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.2697 - val_accuracy: 0.9570 - val_loss: 0.2704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x317275f50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e8ca509-2991-4ce7-91d9-5f7f1f638802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9571 - loss: 0.2709\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_lstm.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cd7f9e8-8e50-4498-b002-8430e97b88b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['LSTM'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "796831cc-8599-4bb2-9329-df368efb5f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GRU\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(50, activation='relu', return_sequences=True))\n",
    "model_gru.add(Dense(10, activation='softmax'))\n",
    "model_gru.compile(optimizer='adam', metrics=['accuracy'], loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "874b51ec-193c-4e8e-8e1a-e1c95567d8d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1237 - loss: 2.2951 - val_accuracy: 0.2224 - val_loss: 2.0837\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2831 - loss: 1.9352 - val_accuracy: 0.4470 - val_loss: 1.4668\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5483 - loss: 1.3152 - val_accuracy: 0.7073 - val_loss: 0.9713\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.8856 - val_accuracy: 0.7981 - val_loss: 0.7002\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.6373 - val_accuracy: 0.8748 - val_loss: 0.5314\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.4846 - val_accuracy: 0.9089 - val_loss: 0.4167\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.3826 - val_accuracy: 0.9289 - val_loss: 0.3402\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.3114 - val_accuracy: 0.9645 - val_loss: 0.2758\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.2541 - val_accuracy: 0.9756 - val_loss: 0.2326\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.2179 - val_accuracy: 0.9509 - val_loss: 0.2669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3172f7910>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "731e6301-49a6-4447-b0a0-3a20e929ea1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9527 - loss: 0.2646\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_gru.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99c692b2-c8f3-4768-b07e-30325fa8f66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['GRU'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acba7d00-7e05-4cb0-98b7-d67f27833ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RNN': 0.8922499418258667,\n",
       " 'LSTM': 0.9569500684738159,\n",
       " 'GRU': 0.9509499669075012}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69f816-845e-4129-b23f-fc043b3c289d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Модели показали отличные результаты – они справляются с запоминанием последовательностей и корректно предсказывают $ y_i $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f8f7ae-1245-4212-85aa-a224e18e9cca",
   "metadata": {},
   "source": [
    "## Решить задачу машинного перевода, выбрав свой язык:\n",
    "\t•\tФормируем датасет с исходного языка на целевой (код прописать в классе).\n",
    "\t•\tСтроим архитектуру нейронной сети.\n",
    "\t•\tОбучаем.\n",
    "\t•\tПроверить качество с помощью метрики BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "304d0b5b-4fe0-484f-a6be-e29af521b2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import time\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b6c7140-0854-4049-887e-bc4a074b08e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Токен начала предложения\n",
    "SOS_token = 0\n",
    "#Токен конца предложения\n",
    "EOS_token = 1\n",
    "\n",
    "class LanguageVocabulary(object):\n",
    "    \"\"\"\n",
    "    Класс для хранения информации о языке и управления словарем токенов.\n",
    "\n",
    "    Атрибуты:\n",
    "        name (str): Название языка.\n",
    "        word2index (dict): Словарь, отображающий слово в его числовой индекс.\n",
    "        word2count (dict): Словарь, содержащий количество встречаемости слов.\n",
    "        index2word (dict): Обратный словарь для word2index.\n",
    "        n_words (int): Количество уникальных слов (включая специальные токены SOS и EOS).\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        Инициализация объекта словаря языка.\n",
    "        \n",
    "        Аргументы:\n",
    "            name (str): Название языка.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "        Добавляет слова из предложения в словарь.\n",
    "        \n",
    "        Аргументы:\n",
    "            sentence (str): Входное предложение.\n",
    "        \"\"\"\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \"\"\"\n",
    "        Добавляет слово в словарь, если оно отсутствует, \n",
    "        либо увеличивает его счетчик.\n",
    "        \n",
    "        Аргументы:\n",
    "            word (str): Слово для добавления.\n",
    "        \"\"\"\n",
    "        if word not in self.word2index:\n",
    "            \n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e34f87e-b417-4764-ac39-e4c1721650b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    \"\"\"\n",
    "    Преобразует строку в ASCII, удаляя диакритические знаки.\n",
    "\n",
    "    Аргументы:\n",
    "        s (str): Входная строка в юникоде.\n",
    "\n",
    "    Возвращает:\n",
    "        str: Строка в ASCII.\n",
    "    \"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "476f03fc-19e2-4051-a41c-88c6808a91d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    \"\"\"\n",
    "    Нормализует строку:\n",
    "    1. Преобразует в ASCII.\n",
    "    2. Приводит к нижнему регистру и убирает пробельные символы с краев.\n",
    "    3. Отделяет знаки препинания (!, ?, .) пробелами.\n",
    "    4. Удаляет все символы, кроме латинских букв и знаков препинания.\n",
    "\n",
    "    Аргументы:\n",
    "        s (str): Входная строка.\n",
    "\n",
    "    Возвращает:\n",
    "        str: Нормализованная строка.\n",
    "    \"\"\"\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "565e87a6-205d-4f75-a0bd-fd1faa42168d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_languages(lang1, lang2, reverse=False):\n",
    "    \"\"\"\n",
    "    Считывает данные из файла корпуса, разбивает их на пары предложений \n",
    "    и нормализует текст.\n",
    "    \n",
    "    Аргументы:\n",
    "        lang1 (str): Код первого языка \n",
    "        lang2 (str): Код второго языка \n",
    "        reverse (bool, optional): Если True, меняет порядок языков (по умолчанию False).\n",
    "    \n",
    "    Возвращает:\n",
    "        tuple: Кортеж из трех элементов:\n",
    "            - input_lang (LanguageVocabulary): Объект словаря для исходного языка.\n",
    "            - output_lang (LanguageVocabulary): Объект словаря для целевого языка.\n",
    "            - pairs (list): Список пар предложений (исходное, целевое).\n",
    "    \"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = LanguageVocabulary(lang2)\n",
    "        output_lang = LanguageVocabulary(lang1)\n",
    "    else:\n",
    "        input_lang = LanguageVocabulary(lang1)\n",
    "        output_lang = LanguageVocabulary(lang2)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e18df62-5e56-403f-92e8-b76c6e79a4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7bd05997-808c-4231-8888-4bd862994660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_pair(p):\n",
    "    \"\"\"\n",
    "    Фильтрует пары предложений, оставляя только те, которые соответствуют заданным условиям.\n",
    "    \n",
    "    Условия:\n",
    "        - Длина предложений (в словах) должна быть меньше MAX_LENGTH.\n",
    "        - Целевое предложение должно начинаться с одного из предопределенных префиксов eng_prefixes.\n",
    "    \n",
    "    Аргументы:\n",
    "        p (tuple): Кортеж из двух строк (исходное предложение, целевое предложение).\n",
    "    \n",
    "    Возвращает:\n",
    "        bool: True, если пара проходит фильтрацию, иначе False.\n",
    "    \"\"\"\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4899909-7b9f-47d2-a77b-9b3265c55999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_pairs(pairs):\n",
    "    \"\"\"\n",
    "    Применяет фильтр к списку пар предложений, оставляя только те, \n",
    "    которые соответствуют заданным условиям.\n",
    "    \n",
    "    Аргументы:\n",
    "        pairs (list): Список пар предложений (кортежи строк).\n",
    "    \n",
    "    Возвращает:\n",
    "        list: Отфильтрованный список пар предложений.\n",
    "    \"\"\"\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d983a488-b837-4708-85f6-bf81fef034fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    \"\"\"\n",
    "    Загружает, фильтрует и подготавливает данные для обучения модели перевода.\n",
    "    \n",
    "    Аргументы:\n",
    "        lang1 (str): Код первого языка \n",
    "        lang2 (str): Код второго языка \n",
    "        reverse (bool, optional): Если True, меняет порядок языков (по умолчанию False).\n",
    "    \n",
    "    Возвращает:\n",
    "        tuple: Кортеж из трех элементов:\n",
    "            - input_lang (LanguageVocabulary): Объект словаря для исходного языка.\n",
    "            - output_lang (LanguageVocabulary): Объект словаря для целевого языка.\n",
    "            - pairs (list): Отфильтрованный список пар предложений (исходное, целевое).\n",
    "    \"\"\"\n",
    "    input_lang, output_lang, pairs = read_languages(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5002ca1-5dd7-4034-b6f9-b672892de564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1aec240-e337-4b4a-b761-4ce5bd6ff354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Кодировщик RNN на основе GRU для последовательного машинного перевода.\n",
    "    \n",
    "    Атрибуты:\n",
    "        hidden_size (int): Размер скрытого состояния GRU.\n",
    "        embedding (nn.Embedding): Слой эмбеддингов для преобразования входных токенов в векторное представление.\n",
    "        gru (nn.GRU): Глубокая рекуррентная сеть GRU, принимающая эмбеддинги и скрытые состояния.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        Инициализирует кодировщик.\n",
    "        \n",
    "        Аргументы:\n",
    "            input_size (int): Размер входного словаря.\n",
    "            hidden_size (int): Размер скрытого состояния GRU.\n",
    "        \"\"\"\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\n",
    "        Пропускает входное слово через эмбеддинги и GRU.\n",
    "        \n",
    "        Аргументы:\n",
    "            input (torch.Tensor): Входной тензор токенов (размерность: 1).\n",
    "            hidden (torch.Tensor): Скрытое состояние (размерность: 1, 1, hidden_size).\n",
    "        \n",
    "        Возвращает:\n",
    "            tuple: Выход из GRU и обновленное скрытое состояние.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"\n",
    "        Инициализирует скрытое состояние нулями.\n",
    "        \n",
    "        Возвращает:\n",
    "            torch.Tensor: Тензор нулей размерности (1, 1, hidden_size).\n",
    "        \"\"\"\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5160b957-d475-4f74-84d0-c755026b1b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Декодер RNN на основе GRU для последовательного машинного перевода.\n",
    "    \n",
    "    Атрибуты:\n",
    "        hidden_size (int): Размер скрытого состояния GRU.\n",
    "        embedding (nn.Embedding): Слой эмбеддингов для представления токенов в виде векторов.\n",
    "        gru (nn.GRU): Глубокая рекуррентная сеть GRU, принимающая эмбеддинги и скрытые состояния.\n",
    "        out (nn.Linear): Полносвязный слой для преобразования выходных данных в размерность словаря.\n",
    "        softmax (nn.LogSoftmax): Функция активации для получения распределения вероятностей по выходным токенам.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Инициализирует декодер.\n",
    "        \n",
    "        Аргументы:\n",
    "            hidden_size (int): Размер скрытого состояния GRU.\n",
    "            output_size (int): Размер выходного словаря.\n",
    "        \"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\n",
    "        Пропускает входное слово через эмбеддинги, GRU и \n",
    "        полносвязный слой для получения предсказанного слова.\n",
    "        \n",
    "        Аргументы:\n",
    "            input (torch.Tensor): Входной тензор токенов (размерность: 1).\n",
    "            hidden (torch.Tensor): Скрытое состояние (размерность: 1, 1, hidden_size).\n",
    "        \n",
    "        Возвращает:\n",
    "            tuple: Выход из GRU и обновленное скрытое состояние.\n",
    "        \"\"\"\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        \"\"\"\n",
    "        Инициализирует скрытое состояние нулями.\n",
    "        \n",
    "        Возвращает:\n",
    "            torch.Tensor: Тензор нулей размерности (1, 1, hidden_size).\n",
    "        \"\"\"\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d8dafe8-b403-495a-94d7-fc9b87d5b2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    Преобразует предложение в список индексов токенов на основе словаря языка.\n",
    "    \n",
    "    Аргументы:\n",
    "        lang (LanguageVocabulary): Объект словаря языка, содержащий маппинг слов в индексы.\n",
    "        sentence (str): Входное предложение, разбитое на слова.\n",
    "    \n",
    "    Возвращает:\n",
    "        list: Список индексов слов, соответствующих токенам в предложении.\n",
    "    \"\"\"\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f7bceb6-7a55-4487-a8d0-eb0258194ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tensorFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    Преобразует предложение в тензор PyTorch, добавляя токен конца предложения (EOS).\n",
    "    \n",
    "    Аргументы:\n",
    "        lang (LanguageVocabulary): Объект словаря языка, содержащий маппинг слов в индексы.\n",
    "        sentence (str): Входное предложение, разбитое на слова.\n",
    "    \n",
    "    Возвращает:\n",
    "        torch.Tensor: Тензор с индексами слов (размерность: [кол-во слов, 1]).\n",
    "    \"\"\"\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8c089c7-fb84-42f5-9fa1-193e8bc3ed74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tensorsFromPair(pair):\n",
    "    \"\"\"\n",
    "    Преобразует пару предложений (входное и целевое) в тензоры.\n",
    "    \n",
    "    Аргументы:\n",
    "        pair (tuple): Кортеж из двух строк (входное предложение, целевое предложение).\n",
    "    \n",
    "    Возвращает:\n",
    "        tuple: Кортеж из двух тензоров:\n",
    "            - input_tensor (torch.Tensor): Тензор с индексами слов для входного языка.\n",
    "            - target_tensor (torch.Tensor): Тензор с индексами слов для целевого языка.\n",
    "    \"\"\"\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eda9bbc9-ecc1-4f63-b1cf-e93b889bc790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Выполняет обучение модели машинного перевода с использованием механизма Teacher Forcing.\n",
    "    \n",
    "    Аргументы:\n",
    "        input_tensor (torch.Tensor): Входное предложение в виде тензора индексов.\n",
    "        target_tensor (torch.Tensor): Целевое предложение в виде тензора индексов.\n",
    "        encoder (nn.Module): Экземпляр энкодера (EncoderRNN).\n",
    "        decoder (nn.Module): Экземпляр декодера (DecoderRNN).\n",
    "        encoder_optimizer (torch.optim.Optimizer): Оптимизатор для энкодера.\n",
    "        decoder_optimizer (torch.optim.Optimizer): Оптимизатор для декодера.\n",
    "        criterion (nn.Module): Функция потерь (например, NLLLoss).\n",
    "        max_length (int, optional): Максимальная длина последовательности (по умолчанию MAX_LENGTH).\n",
    "    \n",
    "    Возвращает:\n",
    "        float: Потери (loss) на текущем примере обучения.\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss.item() / target_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b1df26e-c084-4517-92fe-e0d1f6ebe704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    \"\"\"\n",
    "    Преобразует количество секунд в строку формата 'Xm Ys'.\n",
    "    \n",
    "    Аргументы:\n",
    "        s (float): Время в секундах.\n",
    "    \n",
    "    Возвращает:\n",
    "        str: Строка, представляющая время в минутах и секундах.\n",
    "    \"\"\"\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd295a5d-4e77-4baf-82c5-9cbbf9ecbe48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timeSince(since, percent):\n",
    "    \"\"\"\n",
    "    Вычисляет прошедшее время и оценивает оставшееся время на основе процента выполнения.\n",
    "    \n",
    "    Аргументы:\n",
    "        since (float): Временная метка начала (time.time()).\n",
    "        percent (float): Процент выполнения (от 0 до 1).\n",
    "    \n",
    "    Возвращает:\n",
    "        str: Форматированная строка с прошедшим временем и оставшимся временем.\n",
    "    \"\"\"\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / percent\n",
    "    rs = es - s\n",
    "    return '%s (- eta: %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb3e71b4-f121-43e2-9eaa-1ab91ea28feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Обучает модель машинного перевода на заданном количестве итераций.\n",
    "    \n",
    "    Аргументы:\n",
    "        encoder (nn.Module): Экземпляр энкодера (EncoderRNN).\n",
    "        decoder (nn.Module): Экземпляр декодера (DecoderRNN).\n",
    "        n_iters (int): Количество итераций обучения.\n",
    "        print_every (int, optional): Как часто выводить среднее значение потерь (по умолчанию 1000).\n",
    "        learning_rate (float, optional): Скорость обучения (по умолчанию 0.01).\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    print_loss_total = 0 \n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[epoch - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_iters),\n",
    "                                         epoch, epoch / n_iters * 100, print_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eaa7ca19-f526-4051-be3b-659c27cad489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Выполняет машинный перевод входного предложения с использованием обученного энкодера и декодера.\n",
    "    \n",
    "    Аргументы:\n",
    "        encoder (nn.Module): Экземпляр энкодера (EncoderRNN).\n",
    "        decoder (nn.Module): Экземпляр декодера (DecoderRNN).\n",
    "        sentence (str): Входное предложение для перевода.\n",
    "        max_length (int, optional): Максимальная длина выходного предложения (по умолчанию MAX_LENGTH).\n",
    "    \n",
    "    Возвращает:\n",
    "        list: Список предсказанных слов (включая EOS при завершении перевода).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "            encoder_outputs[i] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = [] \n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b549f114-e979-4525-b9cd-ed404c13ff5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    \"\"\"\n",
    "    Выбирает случайные пары предложений и оценивает качество перевода с помощью модели.\n",
    "\n",
    "    Аргументы:\n",
    "        encoder (nn.Module): Экземпляр энкодера (EncoderRNN).\n",
    "        decoder (nn.Module): Экземпляр декодера (DecoderRNN).\n",
    "        n (int, optional): Количество примеров для оценки (по умолчанию 10).\n",
    "\n",
    "    Возвращает:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6111c9cb-577f-43f4-a820-42d3c33f0adc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 24s (- eta: 19m 39s) (5000 6%) 2.9713\n",
      "2m 49s (- eta: 18m 24s) (10000 13%) 2.4002\n",
      "4m 15s (- eta: 17m 0s) (15000 20%) 2.0644\n",
      "5m 41s (- eta: 15m 38s) (20000 26%) 1.8334\n",
      "7m 9s (- eta: 14m 18s) (25000 33%) 1.6080\n",
      "8m 35s (- eta: 12m 53s) (30000 40%) 1.4543\n",
      "10m 1s (- eta: 11m 27s) (35000 46%) 1.2807\n",
      "11m 27s (- eta: 10m 1s) (40000 53%) 1.1381\n",
      "12m 55s (- eta: 8m 36s) (45000 60%) 1.0428\n",
      "14m 21s (- eta: 7m 10s) (50000 66%) 0.9475\n",
      "15m 48s (- eta: 5m 45s) (55000 73%) 0.8424\n",
      "17m 16s (- eta: 4m 19s) (60000 80%) 0.7278\n",
      "18m 43s (- eta: 2m 52s) (65000 86%) 0.6734\n",
      "20m 16s (- eta: 1m 26s) (70000 93%) 0.6180\n",
      "21m 44s (- eta: 0m 0s) (75000 100%) 0.5467\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94577b3d-0190-458c-8509-195cdb1cfff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> vous m empoisonnez .\n",
      "= you re poisoning me .\n",
      "< you re avoiding me . <EOS>\n",
      "\n",
      "> tu es tres serviable .\n",
      "= you re very helpful .\n",
      "< you re very helpful . <EOS>\n",
      "\n",
      "> tu es trop vieille pour moi .\n",
      "= you re too old for me .\n",
      "< you re too old for me . <EOS>\n",
      "\n",
      "> je suis desolee mais vous devez partir .\n",
      "= i m sorry but you need to leave .\n",
      "< i m sorry but you need to leave . <EOS>\n",
      "\n",
      "> nous sommes serieux .\n",
      "= we re serious .\n",
      "< we re serious . <EOS>\n",
      "\n",
      "> vous n etes pas vous meme aujourd hui .\n",
      "= you re not yourself today .\n",
      "< you re not yourself today . <EOS>\n",
      "\n",
      "> je te donne ce que tu veux .\n",
      "= i m giving you what you want .\n",
      "< i m just you didn t . . <EOS>\n",
      "\n",
      "> nous ne sommes pas jeunes .\n",
      "= we re not young .\n",
      "< we re not young . <EOS>\n",
      "\n",
      "> nous sommes tous retraites .\n",
      "= we re all retired .\n",
      "< we re all crazy . <EOS>\n",
      "\n",
      "> elle est d un naturel calme .\n",
      "= she s a quiet person .\n",
      "< she s a quiet person . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bddd5-121e-46bd-a9bd-642a09ff1276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d0b84-5045-4193-8386-b624f5b9f3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf10132-2f94-418a-944e-b7929412af30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6196acc-0ea9-4674-b18a-6792bc9ea881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
